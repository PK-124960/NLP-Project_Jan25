# import pytesseract
# import pdf2image
# import cv2
# import json
# import os
# import re
# import numpy as np
# from PIL import Image

# # üìå ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Poppler ‡πÅ‡∏•‡∏∞ Tesseract Path
# POPPLER_PATH = r"C:\poppler-24.08.0\Library\bin"
# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
# os.environ["TESSDATA_PREFIX"] = r"C:\Program Files\Tesseract-OCR\tessdata"

# CORRECTION_FILE = "correction_db.json"

# def load_correction_dict():
#     """‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß"""
#     if os.path.exists(CORRECTION_FILE):
#         with open(CORRECTION_FILE, "r", encoding="utf-8") as f:
#             data = json.load(f)
#             return data if isinstance(data, dict) else {}  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ list
#     return {}

# def apply_saved_corrections(text):
#     """üìå ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° OCR ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
#     corrections = load_correction_dict()
#     for wrong, correct in corrections.items():
#         text = text.replace(wrong, correct)
#     return text

# def preprocess_image(image):
#     """ üìå ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô OCR """
#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#     gray = cv2.GaussianBlur(gray, (3,3), 0)
#     gray = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)

#     # ‡∏õ‡∏£‡∏±‡∏ö Adaptive Threshold ‡πÉ‡∏´‡πâ OCR ‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏Ñ‡∏°‡∏Ç‡∏∂‡πâ‡∏ô
#     adaptive_thresh = cv2.adaptiveThreshold(
#         gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 7
#     )
    
#     return adaptive_thresh

# def extract_text_from_pdf(pdf_path):
#     """ üìå ‡πÅ‡∏õ‡∏•‡∏á PDF ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ OCR """
#     images = pdf2image.convert_from_path(pdf_path, dpi=400, poppler_path=POPPLER_PATH)
#     extracted_text = ""
#     for image in images:
#         open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
#         processed_img = preprocess_image(open_cv_image)
        
#         text = pytesseract.image_to_string(processed_img, lang="tha", config="--psm 6 --oem 1")
#         extracted_text += text + "\n\n"
    
#     return extracted_text


# import re

# def extract_sections(ocr_text):
#     """ üìå ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô """
#     sections = {
#         "‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£": "",
#         "‡∏ó‡∏µ‡πà ‡∏Å‡∏´.": "",
#         "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": "",
#         "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á": "",
#         "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": "",
#         "‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á": "",
#         "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢": "",
#         "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤": ""
#     }

#     patterns = {
#         "‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£": r"(‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£[:\s].*?)(?=‡∏ó‡∏µ‡πà|‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà|‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
#         "‡∏ó‡∏µ‡πà ‡∏Å‡∏´.": r"(‡∏ó‡∏µ‡πà ‡∏Å‡∏´.*?)(?=‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà|‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
#         "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": r"(‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà.*?)(?=‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
#         "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á": r"(‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á[:\s].*?)(?=‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
#         "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": r"(‡πÄ‡∏£‡∏µ‡∏¢‡∏ô[:\s].*?)(?=‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á|‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢|\d+\.)",
#         "‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á": r"(‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á[:\s].*?)(?=‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢|\d+\.)",
#         "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢": r"(‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢[:\s].*?)(?=\d+\.)",
#     }

#     for key, pattern in patterns.items():
#         match = re.search(pattern, ocr_text, re.DOTALL)
#         if match:
#             extracted_text = match.group(1).strip()
            
#             # üìå ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥ ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á"
#             if extracted_text.startswith(key):
#                 extracted_text = extracted_text[len(key):].strip()

#             sections[key] = extracted_text

#     # üìå ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å "‡πë." ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á "‡∏à‡∏∂‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏û. ‡∏≠."
#     main_body_match = re.search(r"(\b\d+\..*?)(?=\b‡∏à‡∏∂‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠|\b‡∏û\.\s*‡∏≠\.)", ocr_text, re.DOTALL)

#     sections["‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"] = main_body_match.group(1).strip() if main_body_match else ""

#     # üìå ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
#     for key in sections:
#         if not sections[key]:
#             sections[key] = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

#     return sections


# # üìå ‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î
# CORRECTION_FILE = "ocr_corrections.json"

# def load_correction_dict():
#     """‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß"""
#     if os.path.exists(CORRECTION_FILE):
#         with open(CORRECTION_FILE, "r", encoding="utf-8") as f:
#             data = json.load(f)
#             return data if isinstance(data, dict) else {}  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ list
#     return {}

# def save_correction(word_corrections):
#     """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
#     corrections = load_correction_dict()
#     corrections.update(word_corrections)  # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏±‡∏ö‡πÄ‡∏î‡∏¥‡∏°
#     with open(CORRECTION_FILE, "w", encoding="utf-8") as f:
#         json.dump(corrections, f, ensure_ascii=False, indent=4)

# //-----------------------------------------------//

import pytesseract
import pdf2image
import cv2
import json
import os
import re
import numpy as np
from PIL import Image
from pythainlp.spell import correct
from difflib import get_close_matches

# üìå ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Poppler ‡πÅ‡∏•‡∏∞ Tesseract Path
POPPLER_PATH = r"C:\poppler-24.08.0\Library\bin"
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
os.environ["TESSDATA_PREFIX"] = r"C:\Program Files\Tesseract-OCR\tessdata"

CORRECTION_FILE = "ocr_corrections.json"

def load_correction_dict():
    """‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß"""
    if os.path.exists(CORRECTION_FILE):
        with open(CORRECTION_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data if isinstance(data, dict) else {}
    return {}

def save_correction(word_corrections):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    corrections = load_correction_dict()
    corrections.update(word_corrections)
    with open(CORRECTION_FILE, "w", encoding="utf-8") as f:
        json.dump(corrections, f, ensure_ascii=False, indent=4)

def preprocess_image(image):
    """ üìå ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô OCR """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (3,3), 0)
    gray = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
    adaptive_thresh = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 7
    )
    return adaptive_thresh

def extract_text_from_pdf(pdf_path):
    """ üìå ‡πÅ‡∏õ‡∏•‡∏á PDF ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ OCR (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏´‡∏ô‡πâ‡∏≤) """
    images = pdf2image.convert_from_path(pdf_path, dpi=400, poppler_path=POPPLER_PATH)
    extracted_text = ""
    for i, image in enumerate(images):
        open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        processed_img = preprocess_image(open_cv_image)
        text = pytesseract.image_to_string(processed_img, lang="tha", config="--psm 6 --oem 1")
        extracted_text += f"\n\n--- ‡∏´‡∏ô‡πâ‡∏≤ {i+1} ---\n\n" + text
    return extracted_text

def extract_sections(ocr_text):
    """ üìå ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£ """
    sections = {
        "‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£": "",
        "‡∏ó‡∏µ‡πà ‡∏Å‡∏´.": "",
        "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": "",
        "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á": "",
        "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": "",
        "‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á": "",
        "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢": "",
        "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤": ""
    }
    patterns = {
        "‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£": r"‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£[:\s](.*?)(?=‡∏ó‡∏µ‡πà|‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà|‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
        "‡∏ó‡∏µ‡πà ‡∏Å‡∏´.": r"‡∏ó‡∏µ‡πà ‡∏Å‡∏´[:\s](.*?)(?=‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà|‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
        "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": r"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà[:\s](.*?)(?=‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á|‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
        "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á": r"‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á[:\s](.*?)(?=‡πÄ‡∏£‡∏µ‡∏¢‡∏ô|$)",
        "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": r"‡πÄ‡∏£‡∏µ‡∏¢‡∏ô[:\s](.*?)(?=‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á|‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢|\d+\.)",
        "‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á": r"‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á[:\s](.*?)(?=‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢|\d+\.)",
        "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢": r"‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢[:\s](.*?)(?=\d+\.)"
    }
    for key, pattern in patterns.items():
        match = re.search(pattern, ocr_text, re.DOTALL)
        if match:
            extracted_text = match.group(1).strip()
            sections[key] = extracted_text
    main_body_match = re.search(r"(\b\d+\..*?)(?=\b‡∏à‡∏∂‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠|\b‡∏û\.\s*‡∏≠\.)", ocr_text, re.DOTALL)
    sections["‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"] = main_body_match.group(1).strip() if main_body_match else ""
    for key in sections:
        if not sections[key]:
            sections[key] = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    return sections

def suggest_corrections(text):
    """ üìå ‡πÉ‡∏ä‡πâ PyThaiNLP ‡πÅ‡∏•‡∏∞ difflib ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á """
    words = text.split()
    corrections = load_correction_dict()
    suggestions = {}
    for word in words:
        if word in corrections:
            continue
        corrected_by_model = correct(word)
        closest_match = get_close_matches(word, corrections.keys(), n=1)
        best_suggestion = corrected_by_model if corrected_by_model else (closest_match[0] if closest_match else word)
        suggestions[word] = best_suggestion
    return suggestions
