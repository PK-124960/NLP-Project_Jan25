{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2b79a6",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA check\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca09a8",
   "metadata": {},
   "source": [
    "### Custom Tokenizer creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f25520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load Base Tokenizer\n",
    "base_model_path = \"pythainlp/wangchanglm-7.5B-sft-enth\" \n",
    "print(\"Loading base tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1436ac",
   "metadata": {},
   "source": [
    "#### custum words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the old file\n",
    "with open(\"custom_vocab_5w1h.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# delete duplicated words and rearrange\n",
    "unique_lines = sorted(set(line.strip() for line in lines if line.strip()))\n",
    "\n",
    "print(\"\\n----- words after preprocessing -----\")\n",
    "for line in unique_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "with open(\"custom_vocab_5w1h.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for line in unique_lines:\n",
    "        file.write(line + \"\\n\")\n",
    "\n",
    "print(\"\\nNew words saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc615c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new words\n",
    "with open(\"custom_vocab_5w1h.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    custom_tokens = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "# add new words to tokenizer\n",
    "num_added = tokenizer.add_tokens(custom_tokens)\n",
    "print(f\"‚úÖ Added {num_added} new tokens.\")\n",
    "\n",
    "# save new tokenizer \n",
    "tokenizer.save_pretrained(\"custom_tokenizer_5w1h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ab283",
   "metadata": {},
   "source": [
    "### Step0: Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01724284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Updated_Datasets.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2dd40",
   "metadata": {},
   "source": [
    "### Step1: Load Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ‚úÖ Load Custom Tokenizer\n",
    "tokenizer_path = \"./custom_tokenizer_5w1h\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "print(\"Custom Tokenizer loaded successfully.\")\n",
    "print(\"Vocab size:\", len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed3ddf",
   "metadata": {},
   "source": [
    "#### Tokenization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_check(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None  # ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏∞ return {\"original_text\": None, \"tokens\": [], \"num_tokens\": 0} ‡∏Å‡πá‡πÑ‡∏î‡πâ\n",
    "    encoding = tokenizer(text, add_special_tokens=False, return_tensors=None)\n",
    "    token_ids = encoding['input_ids']\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    return {\n",
    "        \"original_text\": text,\n",
    "        \"tokens\": tokens,\n",
    "        \"num_tokens\": len(tokens)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using Custom Tokenizer\n",
    "def tokenize_and_check(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None  # ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏∞ return {\"original_text\": None, \"tokens\": [], \"num_tokens\": 0} ‡∏Å‡πá‡πÑ‡∏î‡πâ\n",
    "    encoding = tokenizer(text, add_special_tokens=False, return_tensors=None)\n",
    "    token_ids = encoding['input_ids']\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    return {\n",
    "        \"original_text\": text,\n",
    "        \"tokens\": tokens,\n",
    "        \"num_tokens\": len(tokens)\n",
    "    }\n",
    "\n",
    "tokenized_results_input1 = df['Input_Sec1'].apply(tokenize_and_check)\n",
    "\n",
    "for idx, result in enumerate(tokenized_results_input1):\n",
    "    print(f\"\\n==== Record {idx+1} ====\")\n",
    "    print(f\"Original Text: {result['original_text'][:]}\")  \n",
    "    print(f\"Number of Tokens: {result['num_tokens']}\")\n",
    "    print(f\"Tokens: {result['tokens']}\")\n",
    "    if idx >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_results_input2 = df['Input_Sec2'].apply(tokenize_and_check)\n",
    "\n",
    "for idx, result in enumerate(tokenized_results_input2):\n",
    "    print(f\"\\n==== Record {idx+1} ====\")\n",
    "    print(f\"Original Text: {result['original_text'][:]}\")  \n",
    "    print(f\"Number of Tokens: {result['num_tokens']}\")\n",
    "    print(f\"Tokens: {result['tokens']}\")\n",
    "    if idx >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e7675",
   "metadata": {},
   "source": [
    "### Step 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # ‡∏ï‡∏±‡∏î‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô (‡∏à‡∏∏‡∏î, ‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ)\n",
    "    sentences = re.split(r'(?<=[.])\\s+', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    # Boost Formality ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢: ‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≥‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)\n",
    "    replacements = {\n",
    "        \"‡∏ä‡πà‡∏ß‡∏¢\": \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤\",\n",
    "        \"‡∏î‡∏π‡πÅ‡∏•\": \"‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\",\n",
    "        \"‡∏î‡∏π\": \"‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\",\n",
    "        \"‡∏ö‡∏≠‡∏Å\": \"‡πÅ‡∏à‡πâ‡∏á\",\n",
    "        \"‡πÉ‡∏´‡πâ\": \"‡∏≠‡∏ô‡∏∏‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\",\n",
    "    }\n",
    "    boosted_sentences = []\n",
    "    for sentence in sentences:\n",
    "        for informal, formal in replacements.items():\n",
    "            sentence = re.sub(rf'\\b{informal}\\b', formal, sentence)\n",
    "        boosted_sentences.append(sentence)\n",
    "    \n",
    "    return \" \".join(boosted_sentences)\n",
    "\n",
    "df['Input_Sec1'] = df['Input_Sec1'].apply(preprocess_text)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"\\nüßπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Record {idx+1}\")\n",
    "    # print(f\"Original Text:\\n{row['combined_input'][:300]}...\\n\")\n",
    "    print(f\"Preprocessed Text:\\n{row['Input_Sec1'][:300]}...\")\n",
    "    if idx >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Input_Sec2'] = df['Input_Sec2'].apply(preprocess_text)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"\\nüßπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Record {idx+1}\")\n",
    "    # print(f\"Original Text:\\n{row['combined_input'][:300]}...\\n\")\n",
    "    print(f\"Preprocessed Text:\\n{row['Input_Sec2'][:300]}...\")\n",
    "    if idx >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41378236",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Expand abbreviation function\n",
    "def expand_abbreviations(text, abbreviation_dict):\n",
    "    for abbr, full_name in abbreviation_dict.items():\n",
    "        pattern = r'\\b' + re.escape(abbr) + r'\\b'\n",
    "        text = re.sub(pattern, f\"{full_name} ({abbr})\", text)\n",
    "    return text\n",
    "\n",
    "# Example abbreviation dictionary\n",
    "abbreviation_dict = {\n",
    "    \"‡∏Å.‡∏Ñ.\": \"‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°\",\n",
    "    \"‡∏Å.‡∏û.\": \"‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå\",\n",
    "    \"‡∏Å.‡∏¢.\": \"‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô\",\n",
    "    \"‡∏Å‡∏Å‡∏ó.‡∏®‡∏ó‡∏ó.‡∏™‡∏™.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏ó‡∏£‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏° ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏≤‡∏£‡πÇ‡∏ó‡∏£‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡∏ó‡∏´‡∏≤‡∏£ ‡∏Å‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏Å‡∏Å‡∏•.‡∏ö‡∏Å.‡∏™‡∏õ‡∏ó.\": \"‡∏Å‡∏≠‡∏á‡∏Å‡∏•‡∏≤‡∏á ‡∏Å‡∏≠‡∏á‡∏ö‡∏±‡∏ç‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®\",\n",
    "    \"‡∏Å‡∏Ç‡∏™.‡∏¢‡∏ö.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏≠‡∏á‡∏Ç‡∏ô‡∏™‡πà‡∏á ‡∏¢‡∏∏‡∏ó‡∏ò‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏Å‡∏ï‡∏õ.‡∏™‡∏õ‡∏ä.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏õ‡∏•‡∏±‡∏î‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏Å‡∏ï‡∏™.‡∏™‡∏ï‡∏õ.\": \"‡∏Å‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\",\n",
    "    \"‡∏Å‡∏ó‡∏î.‡∏ö‡∏Å.‡∏™‡∏õ‡∏ó.\": \"‡∏Å‡∏≠‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‡∏Å‡∏≠‡∏á‡∏ö‡∏±‡∏ç‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®\",\n",
    "    \"‡∏Å‡∏ó‡∏û.‡∏Å‡∏û.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏≠‡∏á‡∏ó‡∏±‡∏û‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏Å‡∏≠‡∏á‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏•‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏Å‡∏ô‡∏ú.‡∏Å‡∏£.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏≠‡∏á‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô ‡∏Å‡∏£‡∏°‡∏Å‡∏¥‡∏à‡∏Å‡∏≤‡∏£‡∏û‡∏•‡πÄ‡∏£‡∏∑‡∏≠‡∏ô‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏Å‡∏ô‡∏ú.‡∏™‡∏ô‡∏û.‡∏Å‡∏û.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏≠‡∏á‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô ‡∏Å‡∏≠‡∏á‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏•‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏Å‡∏û.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏≠‡∏á‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏•‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏Å‡∏°‡∏®.‡∏ö‡∏Å.‡∏™‡∏õ‡∏ó.\": \"‡∏Å‡∏≠‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡∏Å‡∏≠‡∏á‡∏ö‡∏±‡∏ç‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®\",\n",
    "    \"‡∏Å‡∏£.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏£‡∏°‡∏Å‡∏¥‡∏à‡∏Å‡∏≤‡∏£‡∏û‡∏•‡πÄ‡∏£‡∏∑‡∏≠‡∏ô‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "    \"‡∏™‡∏ö.‡∏ó‡∏´‡∏≤‡∏£\": \"‡∏Å‡∏£‡∏°‡∏™‡∏≤‡∏£‡∏ö‡∏£‡∏£‡∏ì‡∏ó‡∏´‡∏≤‡∏£\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏¢‡πà‡∏≠\n",
    "df['Input_Sec2'] = df['Input_Sec2'].apply(lambda x: expand_abbreviations(x, abbreviation_dict))\n",
    "df['Input_Sec1'] = df['Input_Sec1'].apply(lambda x: expand_abbreviations(x, abbreviation_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38377429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_fewshot(input_sec2, input_sec1):\n",
    "    prompt = f\"\"\"\n",
    "    ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£\n",
    "    ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£\n",
    "    ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î\n",
    "    ‡πÉ‡∏´‡πâ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON\n",
    "\n",
    "    ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏Å‡∏±‡∏î:\n",
    "    \\\"\\\"\\\"{input_sec2}\\\"\\\"\\\"\n",
    "\n",
    "    ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á:\n",
    "    \\\"\\\"\\\"{input_sec1}\\\"\\\"\\\"\n",
    "\n",
    "    ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201f696",
   "metadata": {},
   "source": [
    "### Step 3: Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e72314",
   "metadata": {},
   "source": [
    "#### Abstractive Mode: Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ollama\n",
    "Ollama_API_URL = \"http://localhost:11434/api/chat\"\n",
    "Ollama_Model_Name = \"wangchanglm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cacc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query_ollama_chat(prompt):\n",
    "    payload = {\n",
    "        \"model\": Ollama_Model_Name,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(Ollama_API_URL, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return result['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error calling Ollama: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa21fee",
   "metadata": {},
   "source": [
    "#### Extractive Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02945afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# Config WangchanBERTa (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö extractive)\n",
    "model_name = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def extract_sentences(title, input_sec1, content, top_k=3):\n",
    "    if pd.isnull(title) or pd.isnull(content):\n",
    "        return \"\"\n",
    "    anchor_text = title + \" \" + input_sec1\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', content)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    if not sentences:\n",
    "        return \"\"\n",
    "    anchor_emb = get_sentence_embedding(anchor_text)\n",
    "    sentence_embs = [get_sentence_embedding(sent) for sent in sentences]\n",
    "    sims = [cosine_similarity(anchor_emb, sent_emb)[0][0] for sent_emb in sentence_embs]\n",
    "    top_indices = sorted(range(len(sims)), key=lambda i: sims[i], reverse=True)[:top_k]\n",
    "    selected_sentences = [sentences[i] for i in top_indices]\n",
    "    return ' '.join(selected_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3185714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def rouge_l_score(ref, pred):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    return scorer.score(ref, pred)['rougeL'].fmeasure\n",
    "\n",
    "def bleu_score(ref, pred):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6d914b",
   "metadata": {},
   "source": [
    "#### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT_MODE = [\"extractive\", \"abstractive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0473662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "extractive_outputs = []\n",
    "abstractive_outputs = []\n",
    "human_outputs = df['Output_Sec1'].tolist()\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    title = row['Title']\n",
    "    input_sec1 = row['Input_Sec1']\n",
    "    input_sec2 = row['Input_Sec2']\n",
    "\n",
    "    # Extractive V2\n",
    "    extracted = extract_sentences(title, input_sec1, input_sec2)\n",
    "    extractive_outputs.append(extracted)\n",
    "\n",
    "    # Abstractive V2\n",
    "    input_sec2 = row['Input_Sec2']\n",
    "    prompt = create_prompt_fewshot(input_sec2, input_sec1)\n",
    "    # prompt = create_prompt_abstractive(input_sec2)\n",
    "    summary = query_ollama_chat(prompt)\n",
    "    if summary:\n",
    "        abstractive_outputs.append(summary)\n",
    "    else:\n",
    "        abstractive_outputs.append(\"\")\n",
    "\n",
    "    # # Abstractive V2.1\n",
    "    # summary = generate_summary_openthaigpt(input_sec2)\n",
    "    # abstractive_outputs.append(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53edad4",
   "metadata": {},
   "source": [
    "### Step5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "similarity_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') \n",
    "\n",
    "extractive_rouge = []\n",
    "abstractive_rouge = []\n",
    "extractive_bleu = []\n",
    "abstractive_bleu = []\n",
    "\n",
    "extractive_cosine = []\n",
    "abstractive_cosine = []\n",
    "\n",
    "for human, extr, abstr in tqdm(zip(human_outputs, extractive_outputs, abstractive_outputs), total=len(human_outputs)):\n",
    "    # --- ROUGE-L ---\n",
    "    extractive_rouge.append(rouge_l_score(human, extr))\n",
    "    abstractive_rouge.append(rouge_l_score(human, abstr))\n",
    "\n",
    "    # --- BLEU ---\n",
    "    extractive_bleu.append(bleu_score(human, extr))\n",
    "    abstractive_bleu.append(bleu_score(human, abstr))\n",
    "\n",
    "    # --- Cosine Similarity ---\n",
    "    emb_human = similarity_model.encode(human)\n",
    "    emb_extr = similarity_model.encode(extr)\n",
    "    emb_abstr = similarity_model.encode(abstr)\n",
    "\n",
    "    cosine_extr = cosine_similarity([emb_human], [emb_extr])[0][0]\n",
    "    cosine_abstr = cosine_similarity([emb_human], [emb_abstr])[0][0]\n",
    "\n",
    "    extractive_cosine.append(cosine_extr)\n",
    "    abstractive_cosine.append(cosine_abstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({\n",
    "    \"Human_Reference\": human_outputs,\n",
    "    \"Extractive_Output\": extractive_outputs,\n",
    "    \"Abstractive_Output\": abstractive_outputs,\n",
    "    \"Extractive_ROUGE_L\": extractive_rouge,\n",
    "    \"Abstractive_ROUGE_L\": abstractive_rouge,\n",
    "    \"Extractive_BLEU\": extractive_bleu,\n",
    "    \"Abstractive_BLEU\": abstractive_bleu,\n",
    "    \"Extractive_Cosine\": extractive_cosine,\n",
    "    \"Abstractive_Cosine\": abstractive_cosine\n",
    "})\n",
    "\n",
    "\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_save_path = \"Experiment1_Result.xlsx\"\n",
    "df_result.to_excel(output_save_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ All processing done. Result saved to {output_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel('output.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fb40a",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf453a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πâ‡∏≠ 2 (Fact) ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠ 1 ‡πÅ‡∏ö‡∏ö Fixed Template\n",
    "\n",
    "def create_fixed_fact(input_sec1):\n",
    "    fixed_fact = \"\"\n",
    "    return fixed_fact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_for_section3(input_sec1, fixed_fact, with_feedback=False):\n",
    "    base_prompt = f\"\"\"\n",
    "<fact>\n",
    "‡∏Ç‡πâ‡∏≠ ‡πë: {input_sec1}\n",
    "\n",
    "‡∏Ç‡πâ‡∏≠ ‡πí: {fixed_fact}\n",
    "</fact>\n",
    "\n",
    "<instruction>\n",
    "‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£ (‡∏Ç‡πâ‡∏≠ ‡πì) ‡πÇ‡∏î‡∏¢‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:\n",
    "- ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠ ‡πÜ: 2.1, 2.2, 2.3\n",
    "- ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 3 ‡∏Ç‡πâ‡∏≠\n",
    "- ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏±‡πâ‡∏ô ‡πÜ (1‚Äì2 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)\n",
    "- ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠ ‡πë ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠ ‡πí\n",
    "- ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡πâ‡∏≤‡∏¢\n",
    "</instruction>\n",
    "\"\"\"\n",
    "\n",
    "    if with_feedback:\n",
    "        feedback_example = \"\"\"\n",
    "<example>\n",
    "2.1 ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏ä‡∏¥‡∏ç ‡∏ú‡∏ö.‡∏£‡∏£.‡∏ä‡∏ó. ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏û‡∏¥‡∏ò‡∏µ‡πÄ‡∏õ‡∏¥‡∏î‡∏Ø ‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠ 1\n",
    "2.2 ‡∏Å‡∏™‡∏ô.‡∏Ø ‡∏à‡∏±‡∏î‡∏£‡∏ñ‡∏£‡∏±‡∏ö-‡∏™‡πà‡∏á ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏û‡∏¥‡∏ò‡∏µ‡πÄ‡∏õ‡∏¥‡∏î‡∏Ø\n",
    "2.3 ‡∏ú‡∏ò‡∏Å.‡∏Ø ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≤‡∏£‡∏ö‡∏£‡∏£‡∏ì‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå (ECM) ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ\n",
    "</example>\n",
    "\"\"\"\n",
    "        base_prompt = feedback_example.strip() + \"\\n\" + base_prompt.strip()\n",
    "\n",
    "    return base_prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_best_section3(input_sec1, human_reference_section3, with_feedback=False):\n",
    "    \"\"\"\n",
    "    Generate ‡∏Ç‡πâ‡∏≠ 3 ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (Best Summary, Best Score)\n",
    "    \"\"\"\n",
    "    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠ 2 ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠ 1\n",
    "    fixed_fact = create_fixed_fact(input_sec1)\n",
    "\n",
    "    # ‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Prompt\n",
    "    prompt = create_prompt_for_section3(input_sec1, fixed_fact, with_feedback=with_feedback)\n",
    "\n",
    "    generated_texts = []\n",
    "    scores = []\n",
    "\n",
    "    for _ in range(3):  # ‡∏¢‡∏¥‡∏á 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
    "        gen_text = query_ollama_chat(prompt)\n",
    "        if gen_text:\n",
    "            generated_texts.append(gen_text)\n",
    "            emb_human = similarity_model.encode(human_reference_section3)\n",
    "            emb_generated = similarity_model.encode(gen_text)\n",
    "            score = cosine_similarity([emb_human], [emb_generated])[0][0]\n",
    "            scores.append(score)\n",
    "\n",
    "    if not generated_texts:\n",
    "        return \"\", 0.0\n",
    "\n",
    "    best_idx = np.argmax(scores)\n",
    "    best_text = generated_texts[best_idx]\n",
    "    best_score = scores[best_idx]\n",
    "\n",
    "    # (Optional) Postprocess\n",
    "    # polished_text = rewrite_summary_wangchan(best_text)\n",
    "\n",
    "    return best_text, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡∏°‡∏ï‡∏¥\n",
    "input_sec1 = \"‡∏¢‡∏ö.‡∏ó‡∏´‡∏≤‡∏£ (‡∏™‡∏ô‡∏û.‡∏¢‡∏ö.‡∏ó‡∏´‡∏≤‡∏£) ‡∏Å‡πç‡∏≤‡∏´‡∏ô‡∏î‡∏û‡∏¥‡∏ò‡∏µ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏≠‡∏ö‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ô‡∏≤‡∏¢‡∏ó‡∏´‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ó‡∏ß‡∏ô ‡∏™‡∏≤‡∏¢‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå ‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà 3 ‡∏õ‡∏£‡∏∞‡∏à‡πç‡∏≤‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì ‡∏û.‡∏®. 2568 ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏û‡∏∏‡∏ò‡∏ó‡∏µ‡πà 5 ‡∏û.‡∏¢. 67 ‡πÄ‡∏ß‡∏•‡∏≤ 1300 ‡∏ì ‡∏´‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡∏´‡∏ó‡∏±‡∏¢‡∏ô‡πÄ‡∏£‡∏® ‡∏ä‡∏±‡πâ‡∏ô 2 ‡∏™‡∏ô‡∏û.‡∏¢‡∏ö.‡∏ó‡∏´‡∏≤‡∏£ (‡∏ö‡∏≤‡∏á‡∏ã‡πà‡∏≠‡∏ô) ‡πÇ‡∏î‡∏¢‡∏°‡∏µ ‡∏à‡∏Å.‡∏¢‡∏ö.‡∏ó‡∏´‡∏≤‡∏£ ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏ô‡∏Ø ‡∏Å‡∏≤‡∏£‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏≤‡∏¢ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥ ‡∏Ñ‡∏≠‡∏û‡∏±‡∏ö‡πÅ‡∏Ç‡∏ô‡∏¢‡∏≤‡∏ß (‡∏ó‡∏≠. ‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡∏ò‡∏ô‡∏π‡πÅ‡∏Ç‡πá‡∏á) ‡∏á‡∏î‡∏´‡∏°‡∏ß‡∏Å\"\n",
    "\n",
    "human_reference_section3 = \"\" \\\n",
    "\"2.1 ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏ä‡∏¥‡∏ç ‡∏ú‡∏ö.‡∏£‡∏£.‡∏ä‡∏ó. ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÅ‡∏ó‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏û‡∏¥‡∏ò‡∏µ‡πÄ‡∏õ‡∏¥‡∏î‡∏Ø ‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠ 1\"\n",
    "\"2.2 ‡∏Å‡∏™‡∏ô.‡∏Ø ‡∏à‡∏±‡∏î‡∏£‡∏ñ‡∏£‡∏±‡∏ö-‡∏™‡πà‡∏á ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏û‡∏¥‡∏ò‡∏µ‡πÄ‡∏õ‡∏¥‡∏î‡∏Ø\"\n",
    "\"2.3 ‡∏ú‡∏ò‡∏Å.‡∏Ø ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≤‡∏£‡∏ö‡∏£‡∏£‡∏ì‡∏≠‡∏¥‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏£‡∏≠‡∏ô‡∏¥‡∏Å‡∏™‡πå (ECM) ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏î‡πç‡∏≤‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ\" \\\n",
    "\"\"\n",
    "\n",
    "# ‚úÖ Generate ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ Feedback Correction\n",
    "section3_with_feedback, score_with_feedback = generate_best_section3(\n",
    "    input_sec1, human_reference_section3, with_feedback=True\n",
    ")\n",
    "\n",
    "# ‚úÖ Generate ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ Feedback Correction\n",
    "section3_without_feedback, score_without_feedback = generate_best_section3(\n",
    "    input_sec1, human_reference_section3, with_feedback=False\n",
    ")\n",
    "\n",
    "\n",
    "# ‚úÖ ‡∏î‡∏π‡∏ú‡∏•\n",
    "print(\"\\n‚úÖ Section 3 (With Feedback Correction):\")\n",
    "print(section3_with_feedback)\n",
    "print(\"Cosine Similarity:\", score_with_feedback)\n",
    "\n",
    "print(\"\\n‚úÖ Section 3 (Without Feedback Correction):\")\n",
    "print(section3_without_feedback)\n",
    "print(\"Cosine Similarity:\", score_without_feedback)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
